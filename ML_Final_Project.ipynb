{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maiflys/cs4375-MTranslation/blob/master/ML_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j36yKTdPiRx2",
        "colab_type": "text"
      },
      "source": [
        "#AIS MACHINE TRANSLATION WORKSHOP\n",
        "\n",
        "*Using RNN (Recurrent Neural Network) for Natural Language Processing to translate data from French to English.*\n",
        "\n",
        "\n",
        "By Michael Le, Maitreyee Mhasakar\n",
        "\n",
        "Content and other contributions by Janam Parikh, Arshdeep Singh, Rama Narayan Lakshmanan\n",
        "\n",
        "Github link to resources: [https://github.com/aisutd/Fall19_Workshop2_Machine_Translation](https://github.com/aisutd/Fall19_Workshop2_Machine_Translation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19n_lmRIS4pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "afafec54-2015-4cc0-dfe1-fbab0130dd63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2quj0ay6oDY3",
        "colab_type": "text"
      },
      "source": [
        "## What is Natural Language Processing?\n",
        "\n",
        "Natural Language Processing, usually shortened as NLP,subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
        "\n",
        "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable. Most NLP techniques rely on machine learning to derive meaning from human languages.\n",
        "\n",
        "<img src='https://res.cloudinary.com/rsmglobal/image/fetch/t_default%2Cf_auto%2Cq_auto/https://www.rsm.global/singapore/sites/default/files/media/Publications/Our%20Expert%20Insights/rsm-tmt-nlp.jpg' height=\"500\" width=\"600\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## What is Machine Translation?\n",
        "\n",
        "Machine translation (MT) refers to fully automated software that can translate source content into target languages. \n",
        "Humans may use MT to help them render text and speech into another language, or the MT software may operate without human intervention.\n",
        "\n",
        "\n",
        "Main approaches to machine translation:\n",
        "\n",
        "*   **First-generation rule-based (RbMT) systems** : Based on Grammar, Syntax, Phraseology\n",
        "\n",
        "*   **Statistical systems (SMT)** : Based on Search and Big Data.With lots of parallel texts becoming available, SMT developers learned to pattern-match reference texts to find translations that are statistically most likely to be suitable. These systems train faster than RbMT, provided there is enough existing language material to reference.\n",
        " \n",
        "*   **Neural MT (NMT)** : Machine learning technology to teach software how to produce the best result. This process consumes large amounts of processing power, and that is why it’s often run on graphics units of CPUs. NMT started gaining visibility in 2016. Many MT providers are now switching to this technology.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygqOQ5TIiUYy",
        "colab_type": "code",
        "outputId": "b88e39b1-32a6-4c20-ae2d-2b59f7e51a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "#Importing required libraries\n",
        "\n",
        "import string\n",
        "import re\n",
        "import math\n",
        "import io\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Input, RepeatVector, TimeDistributed, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model, Model\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW6IDhQBrPc7",
        "colab_type": "code",
        "outputId": "45bf6c83-8544-45c5-c68b-9a784e4142fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NifBc-u6k3HP",
        "colab_type": "code",
        "outputId": "5696b584-6342-4c34-be00-1d5cb7e3f04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "#Upload dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96ebb76d-48e2-4d8a-a4ff-d8e3a6768a97\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-96ebb76d-48e2-4d8a-a4ff-d8e3a6768a97\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: google.colab._files is undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crSe10OXgPgf",
        "colab_type": "code",
        "outputId": "726f5da7-fb8f-468e-c435-15430bd6f413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "#Import English sentence data from file into a dataframe\n",
        "english_df = pd.read_csv('/corpus.en_ru.1m.en', sep='\\n', header=None, names=['English'])\n",
        "print(english_df.head())\n",
        "english_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             English\n",
            "0  This new development in Harry's character may ...\n",
            "1  A nondisclosure clause in the final settlement...\n",
            "2  When you're 18 or 19 years old, you have that ...\n",
            "3  Now you have Black Sabbath and Kiss tribute al...\n",
            "4        I was the one who sat down and copied them.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(914541, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb0cMxaygsqR",
        "colab_type": "code",
        "outputId": "901de981-0bd3-4d33-b8a1-e46e7952ad49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "#Import French sentence data from file into a dataframe\n",
        "russian_df = pd.read_csv('/corpus.en_ru.1m.ru', sep='\\n', header=None, names=['Russian'])\n",
        "print(russian_df.head())\n",
        "russian_df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             Russian\n",
            "0  Такое развитие характера Гарри может разочаров...\n",
            "1  Решение суда (группа вернулась под крыло к Ele...\n",
            "2  Когда тебе 18 или 19 лет, легко перенимать бан...\n",
            "3  А сейчас куча триьютов тем же самым BLACK SABB...\n",
            "4  Я был единственным, кто занялся копированием д...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(951318, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QB07PxmlC7b",
        "colab_type": "code",
        "outputId": "eacdb2c5-929d-4c68-8ea8-dac4dfbb446f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "#Final dataset dataframe\n",
        "df = pd.concat([english_df, russian_df], axis=1, join='inner')\n",
        "df.info()\n",
        "print(df.head())\n",
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 914541 entries, 0 to 914540\n",
            "Data columns (total 2 columns):\n",
            "English    914541 non-null object\n",
            "Russian    914541 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 14.0+ MB\n",
            "                                             English                                            Russian\n",
            "0  This new development in Harry's character may ...  Такое развитие характера Гарри может разочаров...\n",
            "1  A nondisclosure clause in the final settlement...  Решение суда (группа вернулась под крыло к Ele...\n",
            "2  When you're 18 or 19 years old, you have that ...  Когда тебе 18 или 19 лет, легко перенимать бан...\n",
            "3  Now you have Black Sabbath and Kiss tribute al...  А сейчас куча триьютов тем же самым BLACK SABB...\n",
            "4        I was the one who sat down and copied them.  Я был единственным, кто занялся копированием д...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(914541, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObJLyKHylisA",
        "colab_type": "code",
        "outputId": "9fa44854-3dc8-455c-9e66-261f36c513e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Remove missing and blank records from data\n",
        "\"\"\"\n",
        "df['English'].replace('', np.nan, inplace=True)\n",
        "df['Russian'].replace('', np.nan, inplace=True)\n",
        "df.dropna(subset=['English'], inplace=True)\n",
        "df.dropna(subset=['Russian'], inplace=True)\n",
        "print(df.shape)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndf['English'].replace('', np.nan, inplace=True)\\ndf['Russian'].replace('', np.nan, inplace=True)\\ndf.dropna(subset=['English'], inplace=True)\\ndf.dropna(subset=['Russian'], inplace=True)\\nprint(df.shape)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mBVkzIbl3j8",
        "colab_type": "code",
        "outputId": "0cc748a8-d1c2-4f28-e932-ac1214fd0209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "#Lowercase english and russian sentences as part of preprocessing\n",
        "df1=df.copy()\n",
        "df1[\"English\"] = df1[\"English\"].str.lower()\n",
        "df1[\"Russian\"] = df1[\"Russian\"].str.lower()\n",
        "print(df1.head())\n",
        "print(df1.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             English                                            Russian\n",
            "0  this new development in harry's character may ...  такое развитие характера гарри может разочаров...\n",
            "1  a nondisclosure clause in the final settlement...  решение суда (группа вернулась под крыло к ele...\n",
            "2  when you're 18 or 19 years old, you have that ...  когда тебе 18 или 19 лет, легко перенимать бан...\n",
            "3  now you have black sabbath and kiss tribute al...  а сейчас куча триьютов тем же самым black sabb...\n",
            "4        i was the one who sat down and copied them.  я был единственным, кто занялся копированием д...\n",
            "(914541, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPY_lYljSrKI",
        "colab_type": "text"
      },
      "source": [
        "## What are Neural Networks?\n",
        "\n",
        "A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. \n",
        "In this sense, neural networks refer to systems of neurons, either organic or artificial in nature. \n",
        "\n",
        "Neural networks can adapt to changing input; so, the network generates the best possible result without needing to redesign the output criteria. \n",
        "\n",
        "The concept of neural networks, which has its roots in artificial intelligence, is swiftly gaining popularity in the development of trading systems.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1592/1*yGMk1GSKKbyKr_cMarlWnA.jpeg'>\n",
        "\n",
        "\n",
        "\n",
        "**Three fundamental components** of neural networks:\n",
        "\n",
        "1. **Structure** - what the neural network looks like, including all the mathematical functions involved, the number of inputs and outputs, and the parameters, called **weights** that the network has to learn.\n",
        "    \n",
        "2. **Loss Function** - a metric that tells us how good or bad the network's predictions are. \n",
        "3. **Optimizer** - the algorithm used for **learning the weights** that give the network the best predictions.\n",
        "\n",
        "\n",
        "### The Simplest Neural Network - The Perceptron\n",
        "The perceptron, arguably the simplest neural network, was invented by psychologist Frank Rosenblatt in 1957 and looks something like this:\n",
        "![perceptron](https://docs.google.com/uc?export=download&id=1SbHK9XPrP1PSO9T-lh9uG9CTCNjdXhU1)\n",
        "\n",
        "(image source: http://ataspinar.com/2016/12/22/the-perceptron/)\n",
        "\n",
        "A perceptron is basically a neural network with a single **artificial neuron**. Similar to the biological neuron, a perceptron has the following characteristics:\n",
        "\n",
        "- **inputs** - the perceptron receives a given number of real-valued inputs (the inputs are numbers).\n",
        "- **weights** - the perceptron has a weight $ w_i $ associated with each input $ x_i $. These weighted connections are like synapses and they are parameters that the perceptron must \"learn\".\n",
        "- **weighted sum (basically a dot product)** - the inputs are multiplied by the weights and the results are added together to produce a weighted sum.\n",
        "- **activation function** - the perceptron has an activation function called the unit-step function that produces an output of 1 if the weighted sum is greater than some threshold $\\theta$ and -1 otherwise.\n",
        "  \n",
        "\n",
        "*tanh*:\n",
        "tanh is like logistic sigmoid but better. The range of the tanh function is from (-1 to 1). tanh is also sigmoidal (s - shaped).\n",
        "\n",
        "![tanh](https://miro.medium.com/max/744/1*f9erByySVjTjohfFdNkJYQ.jpeg)\n",
        "\n",
        "*Softmax*: \n",
        "Softmax function takes a vector as input and produces a vector of the same shape as the output. In a way, this function basically acts on an entire layer. The softmax function basically converts a vector of real values into a probability distribution and is useful for representing the probabilities of different classes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Hidden layers** : layer of neurons other than the input and output layers\n",
        "\n",
        "**Dropout** : Technique to reduce overfitting in neural networks by shutting particular or random neurons at a point of time.\n",
        "\n",
        "**Loss function** :  Method of evaluating how well specific algorithm models the given data. If predictions deviates too much from actual results, loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.\n",
        "\n",
        "*Cross-entropy loss*: measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
        "\n",
        "\n",
        "**Forward Pass**: The forward pass refers to calculation process, values of the output layers from the inputs data. It's traversing through all neurons from first to last layer.\n",
        "\n",
        "**Backpropagation**:\n",
        "Backward pass refers to process of counting changes in weights, using gradient descent algorithm (or similar). Computation is made from last layer, backward to the first layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFQEOXbsqr0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenization\n",
        "def tokenization(sentences):\n",
        "      tokenizer = Tokenizer(lower=False)\n",
        "      tokenizer.fit_on_texts(sentences)\n",
        "      return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp1-UCZgqxtd",
        "colab_type": "code",
        "outputId": "0cd241fd-636b-4458-8944-4bd73b0e7dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#English Tokenization and Unique word/Vocabulary count\n",
        "eng_tokenizer = tokenization(df1[\"English\"].astype('str'))\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 316458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTKrhbgNucNN",
        "colab_type": "code",
        "outputId": "58966a0d-08ff-48de-9506-d29e78627829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Russian Tokenization and Unique word/Vocabulary count\n",
        "\n",
        "rus_tokenizer = tokenization(df1[\"Russian\"].astype('str'))\n",
        "\n",
        "print(f'Russian Vocabulary Size: {len(rus_tokenizer.word_index) + 1}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Russian Vocabulary Size: 629850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-tbQ_nBvUAv",
        "colab_type": "code",
        "outputId": "d3eb582b-fa16-4370-e45f-ec29aa7a84bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "#Convert text to integer sequences for English\n",
        "english_sequences = eng_tokenizer.texts_to_sequences(df1[\"English\"].values)\n",
        "print(english_sequences[0])\n",
        "print(df1[\"English\"].values[0])\n",
        "print(eng_tokenizer.word_index)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5HGMsbkvvMO",
        "colab_type": "code",
        "outputId": "7738f40a-6e5c-4d14-b77e-2545d6117a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "#Convert text to integer sequences for Russian\n",
        "\n",
        "russian_sequences = rus_tokenizer.texts_to_sequences(df1[\"Russian\"].values)\n",
        "print(russian_sequences[0])\n",
        "print(df1[\"Russian\"].values[0])\n",
        "print(rus_tokenizer.word_index)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFsjIJSEyFyd",
        "colab_type": "code",
        "outputId": "05ddac54-79cd-49aa-98ba-7947e1fbf974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#Pad sequences with zeros to amke them of equal length for processing\n",
        "english_sequences = pad_sequences(english_sequences, padding='post')\n",
        "russian_sequences = pad_sequences(russian_sequences, padding='post')\n",
        "print(english_sequences.shape)\n",
        "print(english_sequences[0])\n",
        "print(french_sequences.shape)\n",
        "print(french_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(137860, 15)\n",
            "[17 23  1  8 67  4 39  7  3  1 55  2 44  0  0]\n",
            "(137860, 21)\n",
            "[ 35  34   1   8  67  37  11  24   6   3   1 112   2  50   0   0   0   0\n",
            "   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a68idwNXwMDg",
        "colab_type": "code",
        "outputId": "38b5ca57-442d-4110-b28f-2038f9457f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#Split data into train and test data\n",
        "train_french_input, test_french_input, train_english_output, test_english_output = train_test_split(french_sequences, \n",
        "                                                    english_sequences, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=1)\n",
        "\n",
        "num_train_samples = train_french_input.shape[0]\n",
        "num_test_samples = test_french_input.shape[0]\n",
        "print(f'Number of training samples: {num_train_samples}')\n",
        "print(f'Number of testing samples:  {num_test_samples}')\n",
        "print()\n",
        "\n",
        "max_english_sentence_length = train_french_input.shape[1]\n",
        "max_french_sentence_length = train_french_input.shape[1]\n",
        "print(f'Max english sentence length:    {max_english_sentence_length}')\n",
        "print(f'Max french sentence length:     {max_french_sentence_length}')\n",
        "print()\n",
        "\n",
        "train_french_input = train_french_input.reshape(num_train_samples, max_french_sentence_length, 1)\n",
        "train_english_output = pad_sequences(train_english_output, maxlen=max_french_sentence_length, padding='post')\n",
        "train_english_output = train_english_output.reshape(num_train_samples, max_french_sentence_length, 1)\n",
        "\n",
        "test_french_input = test_french_input.reshape(num_test_samples, max_french_sentence_length, 1)\n",
        "test_english_output = pad_sequences(test_english_output, maxlen=max_french_sentence_length, padding='post')\n",
        "test_english_output = test_english_output.reshape(num_test_samples, max_french_sentence_length, 1)\n",
        "\n",
        "print(f'Train French:   {train_french_input.shape}')\n",
        "print(f'Test French:    {test_french_input.shape}')\n",
        "print(f'Train English:  {train_english_output.shape}')\n",
        "print(f'Test English:   {test_english_output.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 110288\n",
            "Number of testing samples:  27572\n",
            "\n",
            "Max english sentence length:    21\n",
            "Max french sentence length:     21\n",
            "\n",
            "Train French:   (110288, 21, 1)\n",
            "Test French:    (27572, 21, 1)\n",
            "Train English:  (110288, 21, 1)\n",
            "Test English:   (27572, 21, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbqlYKQbTG3C",
        "colab_type": "text"
      },
      "source": [
        "## What are Recurrent Neural Networks?\n",
        "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed graph along a sequence. This allows it to exhibit dynamic temporal behavior for a time sequence. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.\n",
        "\n",
        "\n",
        "RNNs are designed to take sequences of text as inputs or return sequences of text as outputs, or both. \n",
        "\n",
        "They're called recurrent because the network's hidden layers have a loop in which the output from one time step becomes an input at the next time step. This recurrence serves as a form of memory. \n",
        "\n",
        "It allows contextual information to flow through the network so that relevant outputs from previous time steps can be applied to network operations at the current time step. \n",
        "\n",
        "<img src=\"https://qph.fs.quoracdn.net/main-qimg-6eced51767f5bcd94b32bbe50da438e9\">\n",
        "\n",
        "# **Vanishing Gradient Problem **\n",
        "\n",
        "As more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\n",
        "\n",
        "A large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\n",
        "\n",
        "A small gradient means that the weights and biases of the initial layers will not be updated effectively with each training session. Since these initial layers are often crucial to recognizing the core elements of the input data, it can lead to overall inaccuracy of the whole network.\n",
        "\n",
        "\n",
        "\n",
        "## What are LSTMs (Long short-term memory)?\n",
        "\n",
        "Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.\n",
        "\n",
        "\n",
        "A common LSTM unit is composed of a **cell**, an **input gate**, an **output gate** and a **forget gate**. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
        "\n",
        "RNNs using LSTM units partially solve the vanishing gradient problem, because LSTM units allow gradients to also flow unchanged.\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png'>\n",
        "\n",
        "\n",
        "\n",
        "**The cell** : Responsible for keeping track of the dependencies between the elements in the input sequence. \n",
        "\n",
        "**The input gate** : Controls the extent to which a new value flows into the cell.\n",
        "\n",
        "**The forget gate**: Controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. \n",
        "\n",
        "The activation function of the LSTM gates is often the logistic sigmoid function.\n",
        "\n",
        "<img src='https://miro.medium.com/max/2840/1*0f8r3Vd-i4ueYND1CUrhMA.png'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfzeifs8xgRr",
        "colab_type": "code",
        "outputId": "a8ac74c0-fe45-48dc-f59f-01e81c0552ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "english_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "#Create and Build the RNN model\n",
        "model = Sequential()\n",
        "#model.add(Embedding(input_dim=len(fren_tokenizer.word_index) + 1, output_dim=128, mask_zero=True))\n",
        "\n",
        "\n",
        "# return sequences is to get the output of the LSTM for each time step to pass\n",
        "#   to the next layer in the model\n",
        "model.add(LSTM(256, input_shape=train_french_input.shape[1:], return_sequences=True)) # Layer 1 (Input Layer)\n",
        "\n",
        "model.add(TimeDistributed(Dense(512, activation='tanh'))) # Layer 2 (Only hidden layer)\n",
        "\n",
        "# model ouput probabilities for english words from input word\n",
        "model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax'))) # Final (Output) Layer\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12pnwzua0QLl",
        "colab_type": "code",
        "outputId": "abce2608-272b-469d-b1e1-5ea39ff26eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Run the model on training data\n",
        "\n",
        "model.fit(train_french_input, train_english_output, batch_size=1024, epochs=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "110288/110288 [==============================] - 18s 162us/step - loss: 1.9844 - acc: 0.5434\n",
            "Epoch 2/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 1.1812 - acc: 0.6779\n",
            "Epoch 3/50\n",
            "110288/110288 [==============================] - 12s 109us/step - loss: 0.8934 - acc: 0.7373\n",
            "Epoch 4/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.7592 - acc: 0.7637\n",
            "Epoch 5/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.6848 - acc: 0.7788\n",
            "Epoch 6/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.6347 - acc: 0.7888\n",
            "Epoch 7/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.5969 - acc: 0.7962\n",
            "Epoch 8/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.5674 - acc: 0.8030\n",
            "Epoch 9/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.5452 - acc: 0.8070\n",
            "Epoch 10/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.5259 - acc: 0.8131\n",
            "Epoch 11/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.5104 - acc: 0.8162\n",
            "Epoch 12/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4972 - acc: 0.8197\n",
            "Epoch 13/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.4860 - acc: 0.8214\n",
            "Epoch 14/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4758 - acc: 0.8240\n",
            "Epoch 15/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4670 - acc: 0.8251\n",
            "Epoch 16/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4581 - acc: 0.8273\n",
            "Epoch 17/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4514 - acc: 0.8278\n",
            "Epoch 18/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.4442 - acc: 0.8309\n",
            "Epoch 19/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4392 - acc: 0.8316\n",
            "Epoch 20/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4341 - acc: 0.8325\n",
            "Epoch 21/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4283 - acc: 0.8333\n",
            "Epoch 22/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4250 - acc: 0.8347\n",
            "Epoch 23/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4222 - acc: 0.8354\n",
            "Epoch 24/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4170 - acc: 0.8363\n",
            "Epoch 25/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4148 - acc: 0.8376\n",
            "Epoch 26/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.4121 - acc: 0.8380\n",
            "Epoch 27/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.4079 - acc: 0.8387\n",
            "Epoch 28/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.4064 - acc: 0.8385\n",
            "Epoch 29/50\n",
            "110288/110288 [==============================] - 12s 109us/step - loss: 0.4047 - acc: 0.8413\n",
            "Epoch 30/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.4001 - acc: 0.8404\n",
            "Epoch 31/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3992 - acc: 0.8416\n",
            "Epoch 32/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3971 - acc: 0.8424\n",
            "Epoch 33/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3948 - acc: 0.8416\n",
            "Epoch 34/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3937 - acc: 0.8430\n",
            "Epoch 35/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3900 - acc: 0.8436\n",
            "Epoch 36/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3896 - acc: 0.8440\n",
            "Epoch 37/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3871 - acc: 0.8450\n",
            "Epoch 38/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3861 - acc: 0.8451\n",
            "Epoch 39/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3841 - acc: 0.8462\n",
            "Epoch 40/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3825 - acc: 0.8469\n",
            "Epoch 41/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3818 - acc: 0.8468\n",
            "Epoch 42/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3796 - acc: 0.8474\n",
            "Epoch 43/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3792 - acc: 0.8479\n",
            "Epoch 44/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3778 - acc: 0.8485\n",
            "Epoch 45/50\n",
            "110288/110288 [==============================] - 12s 109us/step - loss: 0.3759 - acc: 0.8496\n",
            "Epoch 46/50\n",
            "110288/110288 [==============================] - 12s 106us/step - loss: 0.3751 - acc: 0.8491\n",
            "Epoch 47/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3740 - acc: 0.8506\n",
            "Epoch 48/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3732 - acc: 0.8503\n",
            "Epoch 49/50\n",
            "110288/110288 [==============================] - 12s 108us/step - loss: 0.3723 - acc: 0.8505\n",
            "Epoch 50/50\n",
            "110288/110288 [==============================] - 12s 107us/step - loss: 0.3710 - acc: 0.8506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e4a467438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3tl93igTzCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('50_epochs_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV5tlM7O_ITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load data\n",
        "model = load_model('50_epochs_model.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlELtfDwoX4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict on unseen data\n",
        "sen_prediction = model.predict_classes(test_french_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAAkxhlunQ_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePvVwom4n8TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text=[]\n",
        "for i in sen_prediction:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "      t = get_word(i[j], eng_tokenizer)\n",
        "      if j > 0:\n",
        "        if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "          temp.append('')\n",
        "        else:\n",
        "          temp.append(t)\n",
        "      else:\n",
        "        if(t == None):\n",
        "          temp.append('')\n",
        "        else:\n",
        "          temp.append(t)\n",
        "\n",
        "    preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_-ndicaCJJQ",
        "colab_type": "code",
        "outputId": "3d54b76d-885b-40f8-a234-a81c172e050f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Original Output and Predictions \n",
        "\n",
        "print(f\"Original Sentence:     {' '.join(fren_tokenizer.sequences_to_texts(test_french_input[50]))}\")\n",
        "\n",
        "\n",
        "print(f\"Expected Sentence:     {' '.join(eng_tokenizer.sequences_to_texts(test_english_output[50]))}\")\n",
        "\n",
        "print(\"Predicted Sentence:   \",preds_text[50])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence:     paris est généralement agréable en mars et il est merveilleux à l' automne        \n",
            "Expected Sentence:     paris is usually nice during march and it is wonderful in autumn         \n",
            "Predicted Sentence:    paris is usually pleasant during march and it is usually in autumn         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiupTQc40tx",
        "colab_type": "code",
        "outputId": "154e9a42-e5ee-43fc-eaf1-6a08f8a00579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "print(fren_tokenizer.sequences_to_texts(test_french_input[2]))\n",
        "print(eng_tokenizer.sequences_to_texts(test_english_output[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"l'\", 'inde', 'est', 'doux', 'à', \"l'automne\", 'mais', 'il', 'est', 'jamais', 'chaud', 'au', 'printemps', '', '', '', '', '', '', '', '']\n",
            "['india', 'is', 'mild', 'during', 'fall', 'but', 'it', 'is', 'never', 'warm', 'in', 'spring', '', '', '', '', '', '', '', '', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcdFQMBZ4rXF",
        "colab_type": "code",
        "outputId": "2f905b95-cd84-4606-bf61-c72d10510802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(eng_tokenizer.word_index['autumn'])\n",
        "print(eng_tokenizer.word_index['fall'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}